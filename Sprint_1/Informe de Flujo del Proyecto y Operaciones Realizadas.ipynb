{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Descripci√≥n del flujo de proyecto y las operaciones realizadas en el mismo**\n",
    "\n",
    "-----\n",
    "### üìä **Informe de An√°lisis de la Tabla ‚ÄòTabla_Detallecompras‚Äô** (Rub√©n Hern√°n Pared)\n",
    "\n",
    "#### 1. **Introducci√≥n** üìù\n",
    "Este informe detalla el an√°lisis de la tabla **\"Tabla_Detallecompras\"**. Se utilizaron herramientas como **Python, Excel, Google Sheets y Power BI** para limpiar, explorar y analizar los datos. El objetivo fue asegurar la calidad y utilidad de la informaci√≥n.\n",
    "\n",
    "#### 2. **Herramientas Utilizadas** üõ†Ô∏è\n",
    "- **Python**: Manipulaci√≥n de datos, detecci√≥n de outliers, y visualizaci√≥n.\n",
    "  - Bibliotecas: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`.\n",
    "- **Excel**: Inspecci√≥n inicial y reportes preliminares.\n",
    "- **Google Sheets**: Colaboraci√≥n en tiempo real y an√°lisis ligeros en la nube.\n",
    "- **Power BI**: Visualizaci√≥n avanzada y dashboards interactivos.\n",
    "\n",
    "#### 3. **Variables Analizadas** üìà\n",
    "- **PurchasePrice**: Distribuci√≥n, tendencia central y outliers.\n",
    "- **Quantity**: Relaci√≥n con otras variables y distribuci√≥n.\n",
    "- **Dollars**: An√°lisis de distribuci√≥n, outliers y correlaci√≥n.\n",
    "- **Fechas (PODate, ReceivingDate, InvoiceDate, PayDate)**: An√°lisis de tiempos de entrega y eficiencia en la cadena de suministro.\n",
    "\n",
    "#### 4. **T√©cnicas de Limpieza de Datos** üßπ\n",
    "- **Manejo de Valores Nulos**: Reemplazo de valores en la columna `Size`.\n",
    "- **Correcci√≥n de Tipos de Datos**: Conversi√≥n de fechas y revisi√≥n de formatos num√©ricos.\n",
    "- **Cambio de Nombres de Columnas**: Renombrado para mayor claridad.\n",
    "- **Detecci√≥n de Outliers**: Identificaci√≥n con el m√©todo IQR y an√°lisis de impacto.\n",
    "- **Eliminaci√≥n de Duplicados**: Revisi√≥n y eliminaci√≥n de registros duplicados.\n",
    "\n",
    "#### 5. **Exploraci√≥n de Datos y EDA** üîç\n",
    "- **Tendencia Central**: C√°lculo de media, mediana y moda.\n",
    "- **Dispersi√≥n**: Rango, desviaci√≥n est√°ndar, varianza e IQR.\n",
    "- **Outliers**: Identificaci√≥n y an√°lisis con IQR.\n",
    "- **Correlaci√≥n**: An√°lisis entre variables clave.\n",
    "- **Visualizaci√≥n**: Gr√°ficos de distribuci√≥n y dashboards en Power BI.\n",
    "\n",
    "#### 6. **Resultados y Conclusiones** üèÅ\n",
    "- **Outliers**: Identificaci√≥n de outliers significativos en `PurchasePrice`, `Quantity`, y `Dollars`.\n",
    "- **Relaciones**: Correlaciones entre `PurchasePrice` y `Quantity`, indicando posibles descuentos por volumen.\n",
    "- **Optimizaci√≥n de la Cadena de Suministro**: √Åreas de mejora identificadas en tiempos de entrega.\n",
    "- **Visualizaci√≥n**: Dashboards que facilitan la toma de decisiones.\n",
    "---\n",
    "### üìä **Informe de An√°lisis de la Tabla ‚ÄòProductos‚Äô** (Daniela Forti Ruiz)\n",
    "\n",
    "#### 1. **Colaboraciones** ü§ù\n",
    "- **GitHub**: Desarrollo en equipo del README y aportaci√≥n de logos.\n",
    "- **Trello**: Gesti√≥n de Sprints 1 y 2, asegurando un seguimiento exhaustivo del proyecto.\n",
    "\n",
    "#### 2. **An√°lisis de Datos y Gesti√≥n de Bases de Datos** üíæ\n",
    "- **Python**: Limpieza y preparaci√≥n de datos, tratamiento de valores nulos y EDA.\n",
    "- **SQL Management Studio**: Definici√≥n de claves primarias (PK) y for√°neas (FK) para crear un robusto diagrama de entidad-relaci√≥n.\n",
    "- **Visualizaci√≥n**: Creaci√≥n de distribuciones y an√°lisis de relaciones entre variables.\n",
    "\n",
    "#### 3. **Desarrollo Actual** üöß\n",
    "- **Plantilla de PowerPoint**: En desarrollo para la presentaci√≥n final al cliente, asegurando una comunicaci√≥n clara y profesional de los resultados obtenidos.\n",
    "--- \n",
    "### üìä **Colaboraciones e Informe de An√°lisis de las Tablas ‚ÄòTabla_InventarioInicial‚Äô y ‚ÄòTabla_InventarioFinal‚Äô** (Carlos Fernando Dussan Rivera)\n",
    "\n",
    "#### 1. **Preparaci√≥n del Entorno** ‚öôÔ∏è\n",
    "1. **Instalaci√≥n y carga de librer√≠as**:\n",
    "   - Instal√© **seaborn** para visualizaci√≥n de datos.\n",
    "   - Import√© las librer√≠as: `pandas`, `numpy`, `matplotlib.pyplot`, `seaborn`, y `os`.\n",
    "   - Verifiqu√© las versiones para asegurar la compatibilidad del entorno.\n",
    "2. **Establecimiento del estado de dependencia**:\n",
    "   - Guard√© el estado actual de las dependencias en un archivo `requirementscfdr.txt` usando `pip freeze`, garantizando la replicaci√≥n futura del entorno.\n",
    "\n",
    "#### 2. **Carga y Exploraci√≥n Inicial de los Datos** üìÇ\n",
    "1. **Carga de archivos CSV**:\n",
    "   - Cargu√© los archivos `BegInvFinal12312016.csv` y `EndInvFinal12312016.csv` en DataFrames (`df_BegInvFINAL` y `df_EndInvFINAL`).\n",
    "   - Verifiqu√© que los datos se cargaron correctamente.\n",
    "2. **Verificaci√≥n de la estructura de los DataFrames**:\n",
    "   - Utilic√© `shape` e `info` para revisar la estructura de los DataFrames.\n",
    "   - Identifiqu√© que `df_BegInvFINAL` no conten√≠a valores nulos, mientras que `df_EndInvFINAL` ten√≠a valores nulos en la columna **City**.\n",
    "\n",
    "#### 3. **An√°lisis y Limpieza de Datos** üßπ\n",
    "1. **Integridad de la relaci√≥n Store-City**:\n",
    "   - Agrup√© por **Store** y **City** en `df_BegInvFINAL` para verificar que cada tienda estaba asociada a una √∫nica ciudad.\n",
    "2. **Manejo de valores nulos en City**:\n",
    "   - Identifiqu√© que la tienda **46** ten√≠a valores nulos en `df_EndInvFINAL`.\n",
    "   - Reemplac√© el valor nulo usando la informaci√≥n de `StoreAndCity`, ubicando la tienda 46 en **TYWARDREATH**.\n",
    "3. **Conversi√≥n de columnas de fecha**:\n",
    "   - Convert√≠ las columnas **startDate** y **endDate** a formato `datetime` en ambos DataFrames.\n",
    "4. **Verificaci√≥n de unicidad en identificadores**:\n",
    "   - Confirm√© que la columna **InventoryId** conten√≠a valores √∫nicos en ambos DataFrames.\n",
    "5. **An√°lisis de variabilidad en Brand y Store**:\n",
    "   - Identifiqu√© menos variedad de productos (Brand) en el inventario inicial comparado con el final.\n",
    "   - Detect√© la presencia de una tienda adicional (**tienda 81**) en el inventario final, sugiriendo expansi√≥n o inclusi√≥n tard√≠a de inventario.\n",
    "\n",
    "#### 4. **Transformaci√≥n y An√°lisis Avanzado** üîç\n",
    "1. **Determinaci√≥n de nuevas tiendas y ciudades**:\n",
    "   - Compar√© los valores √∫nicos de **Store** y **City** entre ambos DataFrames.\n",
    "   - Detect√© que **PEMBROKE** y la **tienda 81** aparecieron en el inventario final, indicando una posible expansi√≥n.\n",
    "2. **Creaci√≥n de la columna TotalValue**:\n",
    "   - A√±ad√≠ **TotalValue** (producto de `onHand` y `Price`) en ambos DataFrames para cuantificar el valor total del inventario.\n",
    "3. **An√°lisis comparativo de valor de inventario por ciudad**:\n",
    "   - Agrup√© por **City** y sum√© **TotalValue** para identificar las 10 ciudades principales en t√©rminos de valor de inventario.\n",
    "   - Gener√© gr√°ficos de barras para comparar visualmente estas ciudades entre los periodos inicial y final.\n",
    "4. **An√°lisis comparativo de valor de inventario por producto (Description)**:\n",
    "   - Realic√© un an√°lisis similar para **Description**, comparando el valor total de los productos entre ambos inventarios.\n",
    "   - Filtr√© y grafiqu√© las 10 descripciones de productos con mayor valor en el inventario final.\n",
    "\n",
    "#### 5. **Renombrado de Columnas y Almacenamiento de Resultados** üíæ\n",
    "1. **Renombrado de columnas**:\n",
    "   - Renombr√© las columnas de ambos DataFrames a nombres m√°s descriptivos y en espa√±ol para facilitar su manejo.\n",
    "2. **Almacenamiento de resultados**:\n",
    "   - Guard√© los DataFrames transformados en archivos CSV (`Tabla_InventarioInicial.csv` y `Tabla_InventarioFinal.csv`), asegurando la disponibilidad de los datos para futuros an√°lisis.\n",
    "\n",
    "### **Conclusi√≥n** üèÅ\n",
    "Este proceso de **EDA** y **ETL** no solo limpi√≥ y prepar√≥ los datos, sino que tambi√©n identific√≥ cambios importantes en las operaciones de las tiendas y la distribuci√≥n de productos. La creaci√≥n de visualizaciones y la cuantificaci√≥n del valor del inventario proporcionaron una visi√≥n clara del estado inicial y final del inventario, apoyando decisiones informadas para la gesti√≥n futura. Los resultados fueron documentados y almacenados para facilitar su reutilizaci√≥n en an√°lisis posteriores.\n",
    "\n",
    "---\n",
    "### üìä **Colaboraciones e Informe de An√°lisis de la Tabla ‚ÄòTabla_Compras‚Äô** (Hern√°n Rufino Rom√°n)\n",
    "\n",
    "#### 1. **Creaci√≥n de la Cuenta de GitHub y Organizaci√≥n del Repositorio** üë®‚Äçüíª\n",
    "   - **GitHub**: Se cre√≥ una cuenta para la empresa y se configur√≥ el proyecto en el repositorio.\n",
    "   - **Accesos**: Se otorg√≥ acceso a los miembros del equipo y se organizaron las carpetas para las tareas.\n",
    "#### 2. **An√°lisis ETL y EDA** üìä\n",
    "   - **Carga del CSV**: Se realiz√≥ la carga inicial del archivo en Python.\n",
    "   - **Limpieza y an√°lisis**: \n",
    "     - **Histograma** de la columna **Dollars**.\n",
    "     - **Gr√°fico de dispersi√≥n** entre **Quantity** y **Dollars**.\n",
    "     - **Gr√°fico de barras** para montos por proveedor.\n",
    "     - **Gr√°fico de tendencia temporal** de compras.\n",
    "   - **Subida al repositorio**: Todo el proceso de limpieza y an√°lisis fue documentado y subido a GitHub.\n",
    "#### 3. **Creaci√≥n del Stack Tecnol√≥gico** üõ†Ô∏è\n",
    "   - **Documentaci√≥n**: Se defini√≥ y document√≥ el stack tecnol√≥gico del proyecto, disponible en el repositorio.\n",
    "#### 4. **Configuraci√≥n del Entorno de Desarrollo** üíª\n",
    "   - **M√°quina virtual**: Se cre√≥ una VM para alojar el servidor SQL.\n",
    "   - **Base de datos**: Creaci√≥n de la base de datos, configuraci√≥n de PK y FK, y renombrado de tablas/columnas.\n",
    "   - **Python**: Todo fue realizado en Python y subido al repositorio.\n",
    "#### 5. **Gesti√≥n de Tareas** üìÖ\n",
    "   - **Trello**: Creaci√≥n de cuenta para gestionar tareas.\n",
    "   - **Google Drive**: Se cre√≥ una carpeta para compartir la documentaci√≥n.\n",
    "   - **Power BI**: Conexi√≥n de la base de datos SQL a Power BI y establecimiento de un grupo de trabajo en Power BI Fabric.\n",
    "---\n",
    "### üìä **Colaboraciones e Informe de An√°lisis de la Tabla ‚ÄòTabla_Compras‚Äô** (Marcelo Fabi√°n L√≥pez)\n",
    "\n",
    "#### 1. **Creaci√≥n de Cuenta de Gmail para la Consultora** üìß\n",
    "   - **Gmail**: Se cre√≥ una cuenta de Gmail para la consultora, accesible por los analistas del equipo.\n",
    "#### 2. **Configuraci√≥n en Visual Studio Code y Conexi√≥n a SQL Server** üñ•Ô∏è\n",
    "   - **Librer√≠as**: Se importaron `pandas`, `sqlalchemy`, y `pyodbc`.\n",
    "   - **Conexi√≥n**: Configuraci√≥n de par√°metros de conexi√≥n a SQL Server usando `pyodbc` y `sqlalchemy`.\n",
    "   - **Carga de CSV**: Se carg√≥ el archivo `SalesFINAL12312016.csv` en un DataFrame.\n",
    "   - **Verificaci√≥n**: Se cre√≥ la tabla en SQL Server Management Studio y se corrobor√≥ la importaci√≥n con los primeros 5 registros.\n",
    "#### 3. **Exploratory Data Analysis (EDA) y Extract, Transform, Load (ETL)** üîç\n",
    "   - **Librer√≠as adicionales**: Se instalaron `pandas`, `numpy`, `matplotlib`, `seaborn`, `sqlalchemy`, y `pyodbc`.\n",
    "   - **Inspecci√≥n inicial**: \n",
    "     - Visualizaci√≥n de las primeras 5 filas.\n",
    "     - Estad√≠sticas descriptivas y verificaci√≥n de tipos de datos.\n",
    "   - **Conversi√≥n**: Se optimiz√≥ el formato de columnas clave, como `SalesDate` y `Volume`.\n",
    "   - **Detecci√≥n de nulos y duplicados**: Se buscaron nulos y duplicados, sin encontrar ninguno.\n",
    "   - **Visualizaci√≥n**: \n",
    "     - `histplot` de distribuci√≥n de ventas por precio de producto.\n",
    "     - `scatterplot` para relacionar `SalesPrice` y `SalesQuantity`.\n",
    "   - **Funci√≥n estad√≠stica**: Creaci√≥n de funci√≥n para calcular mediana, varianza, rango, y moda.\n",
    "   - **Verificaci√≥n final**: Se revisaron los tipos de datos despu√©s de la formateaci√≥n.\n",
    "#### 4. **ETL desde Visual Studio Code y a trav√©s de Python** ‚öôÔ∏è\n",
    "   - **Renombrado de tabla y columnas**: \n",
    "     - Renombramiento de la tabla como `Tabla_VentasFinal`.\n",
    "     - Ajustes en formatos de columnas para establecer FK.\n",
    "   - **Creaci√≥n de PK**: Se cre√≥ la columna `VentasID` como PK de la tabla.\n",
    "   - **Limpieza de datos**: Establecimiento de valores `NULL` para FK sin correspondencia en tablas relacionadas.\n",
    "   - **Resoluci√≥n de problemas**: Gesti√≥n de FK con nombres diferentes debido a problemas en la creaci√≥n.\n",
    "\n",
    "-----\n",
    "### **Conclusi√≥n Final** üèÅ\n",
    "\n",
    "Estos informes reflejan un proceso exhaustivo de an√°lisis y transformaci√≥n de datos, centrado en la preparaci√≥n de los entornos de desarrollo, la configuraci√≥n de conexiones a bases de datos, y la ejecuci√≥n de procesos ETL y EDA. La colaboraci√≥n y la gesti√≥n de tareas fueron fundamentales para el √©xito de estos proyectos, asegurando una documentaci√≥n precisa y accesible en repositorios compartidos. La creaci√≥n de gr√°ficos y la implementaci√≥n de soluciones para problemas de integridad en los datos destacan la capacidad de los equipos para adaptarse y resolver desaf√≠os t√©cnicos.\n",
    "\n",
    "El trabajo meticuloso en la limpieza, estructuraci√≥n y an√°lisis de datos proporcion√≥ una base s√≥lida para la toma de decisiones, permitiendo identificar patrones, tendencias y posibles √°reas de expansi√≥n o mejora en las operaciones. La integraci√≥n de herramientas como GitHub, Power BI, y SQL Server consolid√≥ el enfoque colaborativo y tecnol√≥gico, alineado con los objetivos del an√°lisis de inventarios y ventas.\n",
    "Este conjunto de procesos y documentaciones subraya la importancia de la organizaci√≥n, la atenci√≥n al detalle y la capacidad de adaptaci√≥n en proyectos de an√°lisis de datos complejos, contribuyendo a un entorno de desarrollo eficiente y a resultados anal√≠ticos robustos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
